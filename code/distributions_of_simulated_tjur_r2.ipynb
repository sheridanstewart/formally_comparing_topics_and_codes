{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_chunks(list_, n_per_chunk_):\n",
    "    \"\"\"Handle output from R\"\"\"\n",
    "    for i in range(0, len(list_), n_per_chunk_):  \n",
    "        yield list_[i:i + n_per_chunk_]\n",
    "        \n",
    "\n",
    "def docs_as_dists(topic_list_):\n",
    "    \"\"\"Represent each document as a distribution of topic probabilities\"\"\"\n",
    "    topic_lengths = set(len(topic_) for topic_ in topic_list_)\n",
    "    assert len(topic_lengths) == 1\n",
    "    response_vecs_ = []\n",
    "    num_topics = len(topic_list_)\n",
    "    topic_len = list(topic_lengths)[0]\n",
    "    for i in range(topic_len):\n",
    "        vec = []\n",
    "        for j in range(num_topics):\n",
    "            val = topic_list_[j][i]\n",
    "            vec.append(val)\n",
    "        response_vecs_.append(vec)\n",
    "    return response_vecs_\n",
    "\n",
    "\n",
    "def tjur_r2_ALL(X_df, y_df):\n",
    "    \"\"\"\n",
    "    Tjur, T. (2009). Coefficients of determination in logistic regression \n",
    "    modelsâ€”a new proposal: The coefficient of discrimination. The American \n",
    "    Statistician, 63(4),366-372. DOI: 10.1198/tast.2009.08210\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    r2s = []\n",
    "    y_cols = y_df.columns\n",
    "    X_cols = X_df.columns\n",
    "    X = X_df[X_cols].to_numpy()\n",
    "    for y_col in y_cols:\n",
    "        y = y_df[y_col].values\n",
    "        r2_row = []\n",
    "        for x_col in X_cols:\n",
    "            X = X_df[x_col].values.reshape(-1,1)\n",
    "            logit = LogisticRegression(penalty='none', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, max_iter=200, multi_class='auto', verbose=0).fit(X, y)\n",
    "            yhat = logit.predict_proba(X)\n",
    "            yhat = [yh[1] for yh in yhat]\n",
    "            response = pd.DataFrame(list(zip(y, yhat)), columns=[\"y\", \"yhat\"])\n",
    "            r2 = np.mean(response[response[\"y\"]==True][\"yhat\"]) - np.mean(response[response[\"y\"]==False][\"yhat\"])\n",
    "            r2_row.append(r2)\n",
    "            if r2 >= 0.2:\n",
    "                print(x_col, y_col)\n",
    "            count += 1\n",
    "        X = X_df[X_cols].to_numpy()\n",
    "        logit = LogisticRegression(penalty='none', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, max_iter=200, multi_class='auto', verbose=0).fit(X, y)\n",
    "        yhat = logit.predict_proba(X)\n",
    "        yhat = [yh[1] for yh in yhat]\n",
    "        response = pd.DataFrame(list(zip(y, yhat)), columns=[\"y\", \"yhat\"])\n",
    "        r2_full = np.mean(response[response[\"y\"]==True][\"yhat\"]) - np.mean(response[response[\"y\"]==False][\"yhat\"])\n",
    "        r2_row.append(r2_full)\n",
    "        r2s.append(r2_row)\n",
    "    return np.array(r2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_sims = \"simulated_corpora/\"\n",
    "\n",
    "fs1 = [f for f in os.listdir(path_to_sims) if \"ngrams_df_sim\" in f]\n",
    "\n",
    "fs2 = [f for f in os.listdir(path_to_sims) if \"topicmodel_k15_sim\" in f]\n",
    "fs3 = [f for f in os.listdir(path_to_sims) if \"topic_probs_k15_sim\" in f]\n",
    "fs4 = [f for f in os.listdir(path_to_sims) if \"_lda15gamma\" in f]\n",
    "fs5 = [f for f in os.listdir(path_to_sims) if \"_lda15beta\" in f]\n",
    "fs6 = [f for f in os.listdir(path_to_sims) if \"likeliest_terms_k15\" in f]\n",
    "\n",
    "fs7 = [f for f in os.listdir(path_to_sims) if \"topicmodel_k35_sim\" in f]\n",
    "fs8 = [f for f in os.listdir(path_to_sims) if \"topic_probs_k35_sim\" in f]\n",
    "fs9 = [f for f in os.listdir(path_to_sims) if \"_lda35gamma\" in f]\n",
    "fs10 = [f for f in os.listdir(path_to_sims) if \"_lda35beta\" in f]\n",
    "fs11 = [f for f in os.listdir(path_to_sims) if \"likeliest_terms_k35\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = [fs1, fs2, fs3, fs4, fs5, fs6, fs7, fs8, fs9, fs10, fs11]\n",
    "\n",
    "for f in fs:\n",
    "    print(len(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = \"sim[0-9]{1,4}\"\n",
    "\n",
    "sim_nums = []\n",
    "\n",
    "for i, f in enumerate(fs[1:]):\n",
    "    f = [int(re.findall(reg, f_)[0].replace(\"sim\", \"\")) for f_ in f]\n",
    "    sim_nums += f\n",
    "\n",
    "c = Counter(sim_nums)\n",
    "for value in c.values():\n",
    "    assert value == 10 # assert simulation number occurs only once in each file list\n",
    "    \n",
    "sim_nums = set(sim_nums)\n",
    "print(len(sim_nums))\n",
    "print(min(sim_nums))\n",
    "print(max(sim_nums))\n",
    "\n",
    "missing = [i for i in range(1,1085) if i not in sim_nums]\n",
    "print(len(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df15 = pd.read_csv(\"df_for_comparison_k15.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df15.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df15.columns)[13:-18]\n",
    "cols.remove(\"Index Codes Applied\")\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_cols = ['Academic Medicine Applied',\n",
    " 'Culture of medicine Applied',\n",
    " 'Expectations Applied',\n",
    " 'Hospital/clinic hours and environment Applied',\n",
    " 'Incentive/payment structure Applied',\n",
    " 'Interpersonal Applied',\n",
    " 'Job changes Applied',\n",
    " 'Medical training Applied',\n",
    " 'Missed opportunities Applied',\n",
    " 'Pay/Compensation Applied',\n",
    " 'Psychological Applied',\n",
    " 'Sub-specialities Applied',\n",
    " 'Great quote/example Applied',\n",
    " 'Motherhood Specific Applied',\n",
    " 'Motherhood Specific/Breastfeeding/Pumping Applied',\n",
    " 'Motherhood Specific/Childcare/Household challenges Applied',\n",
    " 'Motherhood Specific/Family leave Applied']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cols == orig_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qual = df15[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_cols = [f\"topic_{i}\" for i in range(1,36)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "lengths = set()\n",
    "\n",
    "cell_types = set()\n",
    "zero_cells = 0\n",
    "\n",
    "r2s_dict_k15 = defaultdict(lambda: defaultdict(lambda: []))\n",
    "r2s_dict_k35 = defaultdict(lambda: defaultdict(lambda: []))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for sim in sorted(list(sim_nums)):\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    f = f\"{path_to_sims}/topic_probs_k15_sim{sim}.txt\"\n",
    "    doc15 = open(f, \"r\").read().split()\n",
    "    topic_list15 = [chunk for chunk in separate_chunks(doc15, 988)]\n",
    "    response_vecs15 = docs_as_dists(topic_list15)\n",
    "    lengths.add(len(response_vecs15))\n",
    "\n",
    "    df_k15 = pd.DataFrame(response_vecs15, columns=topic_cols[:15])\n",
    "    \n",
    "    r2s = tjur_r2_ALL(df_k15, df_qual)\n",
    "    \n",
    "    for row_i in range(r2s.shape[0]):\n",
    "        for col_j in range(r2s.shape[1]):\n",
    "            cell_r2 = r2s[row_i][col_j]\n",
    "            cell_types.add(type(cell_r2))\n",
    "            if cell_r2 == 0.0:\n",
    "                zero_cells += 1\n",
    "            r2s_dict_k15[row_i][col_j].append(cell_r2)   \n",
    "    \n",
    "    f = f\"{path_to_sims}/topic_probs_k35_sim{sim}.txt\"\n",
    "    doc35 = open(f, \"r\").read().split()\n",
    "    topic_list35 = [chunk for chunk in separate_chunks(doc35, 988)]\n",
    "    response_vecs35 = docs_as_dists(topic_list35)\n",
    "    lengths.add(len(response_vecs35))\n",
    "\n",
    "    df_k35 = pd.DataFrame(response_vecs35, columns=topic_cols)\n",
    "    \n",
    "    r2s = tjur_r2_ALL(df_k35, df_qual)\n",
    "    \n",
    "    for row_i in range(r2s.shape[0]):\n",
    "        for col_j in range(r2s.shape[1]):\n",
    "            cell_r2 = r2s[row_i][col_j]\n",
    "            cell_types.add(type(cell_r2))\n",
    "            if cell_r2 == 0.0:\n",
    "                zero_cells += 1\n",
    "            r2s_dict_k35[row_i][col_j].append(cell_r2)\n",
    "            \n",
    "    if count % 100 == 0:\n",
    "        print(f\"Processed {count}.\", \"{:.2f} seconds elapsed.\".format(time.time() - start_time))\n",
    "        \n",
    "print(\"Finished. {:.2f} seconds elapsed.\".format(time.time() - start_time))\n",
    "\n",
    "print(cell_types) \n",
    "print(count)\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k15_dict = defaultdict(lambda: {})\n",
    "for key_i in r2s_dict_k15.keys():\n",
    "    for key_j in r2s_dict_k15[key_i].keys():\n",
    "        cell_r2s = r2s_dict_k15[key_i][key_j]\n",
    "        k15_dict[key_i][key_j] = cell_r2s\n",
    "        \n",
    "k35_dict = defaultdict(lambda: {})\n",
    "for key_i in r2s_dict_k35.keys():\n",
    "    for key_j in r2s_dict_k35[key_i].keys():\n",
    "        cell_r2s = r2s_dict_k35[key_i][key_j]\n",
    "        k35_dict[key_i][key_j] = cell_r2s\n",
    "        \n",
    "k15_dict = dict(k15_dict)\n",
    "k35_dict = dict(k35_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(17):\n",
    "    for j in range(15):\n",
    "        assert k15_dict[i][j] == r2s_dict_k15[i][j]\n",
    "    for j in range(35):\n",
    "        assert k35_dict[i][j] == r2s_dict_k35[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = set()\n",
    "\n",
    "print(len(r2s_dict_k15.keys())) # 17 codes\n",
    "print(len(r2s_dict_k15[0].keys())) # 15 topics + full model = 16\n",
    "\n",
    "for row, col in r2s_dict_k15.items():\n",
    "    for cell in col.values():\n",
    "        lengths.add(len(cell))\n",
    "        \n",
    "print(len(r2s_dict_k35.keys())) # 17 codes\n",
    "print(len(r2s_dict_k35[0].keys())) # 35 topics + full model = 36\n",
    "        \n",
    "for row, col in r2s_dict_k35.items():\n",
    "    for cell in col.values():\n",
    "        lengths.add(len(cell))\n",
    "        \n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outf = \"simulations_tjur_r2_k15.d\"\n",
    "pickle.dump(k15_dict, open(outf, \"wb\"))\n",
    "\n",
    "outf = \"simulations_tjur_r2_k35.d\"\n",
    "pickle.dump(k35_dict, open(outf, \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
